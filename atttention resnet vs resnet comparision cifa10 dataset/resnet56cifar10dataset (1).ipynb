{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import BatchNormalization, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout ,ZeroPadding2D\nfrom keras.layers import Add, Dense, Activation,    BatchNormalization, Flatten,Input \nfrom keras.layers import AveragePooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Activation\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout\nfrom keras.models import Model\nimport numpy as np\nfrom keras import layers, utils, regularizers\nfrom keras.regularizers import l2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam,SGD\nimport keras\nimport matplotlib.pyplot as plt\nimport sys\nimport numpy as np\nimport os\nprint(os.listdir(\"../input\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"185d98f0f9b183a6daa29e9c40c8865d0e981458","_kg_hide-input":true},"cell_type":"code","source":"from os import listdir, makedirs\nfrom os.path import join, exists, expanduser\n\ncache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\ndatasets_dir = join(cache_dir, 'datasets') # /cifar-10-batches-py\nif not exists(datasets_dir):\n    makedirs(datasets_dir)\n\n\n!cp ../input/cifar-10-python.tar.gz ~/.keras/datasets/\n!ln -s  ~/.keras/datasets/cifar-10-python.tar.gz ~/.keras/datasets/cifar-10-batches-py.tar.gz\n!tar xzvf ~/.keras/datasets/cifar-10-python.tar.gz -C ~/.keras/datasets/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c9d3f9cf2232a09ed3fd581079665dd3d8b43f0"},"cell_type":"code","source":"import keras\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\n# Load CIFAR10 data\n(x_train, y_train), (x_test, y_test)  = keras.datasets.cifar10.load_data()\n\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# define generators for training and validation data\ntrain_datagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\nval_datagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True)\n\n# compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied)\ntrain_datagen.fit(x_train)\nval_datagen.fit(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(x_train))\nfor i in range(1,9):\n    plt.imshow(x_train[i])\n    plt.show()\n    \n    i=i+1\n\n     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" \nimport keras.backend as K\nK.set_image_data_format('channels_last')\nK.set_learning_phase(1)\n\n\n \nclasses = 10\nepochs = 50\nbatch_size = 32\npatience = 7\n\ndef identity_block(X, f, filters, stage, block):\n \n    \n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value. You'll need this later to add back to the main path. \n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a')(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    # Second component of main path \n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same', name = conv_name_base + '2b')(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X) \n\n    # Third component of main path\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c')(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X) \n    \n    return X\n\ndef convolutional_block(X, f, filters, stage, block, s = 2):\n \n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n    # First component of main path \n    X = Conv2D(F1, (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '2a')(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    # Second component of main path \n    X = Conv2D(F2, (f, f), strides = (1, 1), padding = 'same', name = conv_name_base + '2b')(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path \n    X = Conv2D(F3, (1, 1), strides = (1, 1), padding = 'valid', name = conv_name_base + '2c')(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    # Shortcut path\n    X_shortcut = Conv2D(F3, (1, 1), strides = (s, s), padding = 'valid', name = conv_name_base + '1')(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef ResNet56(input_shape = (32, 32, 3)):\n\n    \n    X_input = Input(input_shape)\n    \n    # Zero-Padding\n    X = ZeroPadding2D((2, 2))(X_input)\n    \n    # Stage 1\n    X = Conv2D(64, (4, 4), strides = (1, 1), name = 'conv1')(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n    # Stage 3 \n    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block = 'a', s = 2)\n    X = identity_block(X, f = 3, filters = [128, 128, 512], stage = 3, block = 'b')\n    X = identity_block(X, f = 3, filters = [128, 128, 512], stage = 3, block = 'c')\n    X = identity_block(X, f = 3, filters = [128, 128, 512], stage = 3, block = 'd')\n\n    # Stage 4 \n    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block = 'a', s = 2)\n    X = identity_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block = 'b')\n    X = identity_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block = 'c')\n    X = identity_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block = 'd')\n    X = identity_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block = 'e')\n    X = identity_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block = 'f')\n\n    # Stage 5 \n    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block = 'a', s = 2)\n    X = identity_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block = 'b')\n    X = identity_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block = 'c')\n\n    # AVGPOOL \n    X = AveragePooling2D((2, 2), name = 'avg_pool')(X)\n\n    # output layer\n    X = Flatten()(X)\n    X = Dense(512, activation = 'relu', kernel_regularizer=regularizers.l2(0.01))(X)\n    X = Dropout(0.55)(X)\n    X = Dense(classes, activation = 'softmax', kernel_regularizer=regularizers.l2(0.01))(X)\n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ResNet56()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_reducer = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=7, min_lr=10e-7, epsilon=0.01, verbose=1)\nearly_stopper = EarlyStopping(monitor='val_acc', min_delta=0, patience=15, verbose=1)\ncallbacks= [lr_reducer, early_stopper]\n \n# define loss, metrics, optimizer\nmodel.compile(keras.optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n \n# fits the model on batches with real-time data augmentation\nbatch_size = 32\n\nmodel.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n                    steps_per_epoch=len(x_train)//batch_size, epochs=40,\n                    validation_data=val_datagen.flow(x_test, y_test, batch_size=batch_size), \n                    validation_steps=len(x_test)//batch_size,\n                    callbacks=callbacks, initial_epoch=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate_generator(val_datagen.flow(x_test,y_test), steps= len(x_test)/32, use_multiprocessing = True )\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}